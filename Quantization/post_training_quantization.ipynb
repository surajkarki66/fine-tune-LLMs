{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "As77XeI3xXW8"
      },
      "source": [
        "# Post Training Quantization\n",
        "In this notebook, we will implementing one of the modes of quantization called Post Training Quantization using PyTorch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EWZusX5xXXA"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "x_vJkJzGxXXB"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the FashionMNIST Dataset"
      ],
      "metadata": {
        "id": "sMqw_pzaxqXo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TBZ1OlbXxXXD"
      },
      "outputs": [],
      "source": [
        "# Make torch deterministic\n",
        "_ = torch.manual_seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
        "\n",
        "# Load the FashionMNIST dataset\n",
        "fmnist_trainset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "# Create a dataloader for the training\n",
        "train_loader = torch.utils.data.DataLoader(fmnist_trainset, batch_size=16, shuffle=True)\n",
        "\n",
        "# Load the FashionMNIST test set\n",
        "fmnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(fmnist_trainset, batch_size=16, shuffle=True)\n",
        "\n",
        "# Define the device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yvd_YnZB1jEM",
        "outputId": "55080248-2bd3-4ab7-ba3e-7c8e4bf43944"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:03<00:00, 7688938.22it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 139658.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:01<00:00, 2511678.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 18743296.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 89183050.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 75192857.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 24696436.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 4263770.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the Model"
      ],
      "metadata": {
        "id": "Afjbo-o44e6r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FashionNet(nn.Module):\n",
        "    def __init__(self, hidden_size_1=128, hidden_size_2=256):\n",
        "        super(FashionNet,self).__init__()\n",
        "        self.linear1 = nn.Linear(28*28, hidden_size_1)\n",
        "        self.linear2 = nn.Linear(hidden_size_1, hidden_size_2)\n",
        "        self.linear3 = nn.Linear(hidden_size_2, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, img):\n",
        "        x = img.view(-1, 28*28)\n",
        "        x = self.relu(self.linear1(x))\n",
        "        x = self.relu(self.linear2(x))\n",
        "        x = self.linear3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "_uG4ajRe4bRS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = FashionNet().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUV-TEx847j0",
        "outputId": "230eb64f-d9f3-4d8d-ce48-f9e1c88087cf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FashionNet(\n",
            "  (linear1): Linear(in_features=784, out_features=128, bias=True)\n",
            "  (linear2): Linear(in_features=128, out_features=256, bias=True)\n",
            "  (linear3): Linear(in_features=256, out_features=10, bias=True)\n",
            "  (relu): ReLU()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the Model"
      ],
      "metadata": {
        "id": "LVYz2TQS5CKP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_loader, model, epochs=5, total_iterations_limit=None):\n",
        "    cross_el = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    total_iterations = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "\n",
        "        loss_sum = 0\n",
        "        num_iterations = 0\n",
        "\n",
        "        data_iterator = tqdm(train_loader, desc=f'Epoch {epoch+1}')\n",
        "        if total_iterations_limit is not None:\n",
        "            data_iterator.total = total_iterations_limit\n",
        "\n",
        "        for data in data_iterator:\n",
        "            num_iterations += 1\n",
        "            total_iterations += 1\n",
        "            x, y = data\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(x.view(-1, 28*28))\n",
        "            loss = cross_el(output, y)\n",
        "            loss_sum += loss.item()\n",
        "            avg_loss = loss_sum / num_iterations\n",
        "            data_iterator.set_postfix(loss=avg_loss)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if total_iterations_limit is not None and total_iterations >= total_iterations_limit:\n",
        "                return"
      ],
      "metadata": {
        "id": "Po54D74T5AIE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_FILENAME = 'fashion_net.pt'\n",
        "\n",
        "if Path(MODEL_FILENAME).exists():\n",
        "    model.load_state_dict(torch.load(MODEL_FILENAME))\n",
        "    print('Loaded model from disk')\n",
        "else:\n",
        "    train(train_loader, model, epochs=10)\n",
        "    # Save the model to disk\n",
        "    torch.save(model.state_dict(), MODEL_FILENAME)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oC7RlBf55stn",
        "outputId": "ac2ad62c-41d8-4d5f-a3f4-56674bd0d80d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 3750/3750 [00:45<00:00, 82.17it/s, loss=0.458]\n",
            "Epoch 2: 100%|██████████| 3750/3750 [00:47<00:00, 79.21it/s, loss=0.355]\n",
            "Epoch 3: 100%|██████████| 3750/3750 [00:45<00:00, 82.26it/s, loss=0.32]\n",
            "Epoch 4: 100%|██████████| 3750/3750 [00:46<00:00, 80.21it/s, loss=0.301]\n",
            "Epoch 5: 100%|██████████| 3750/3750 [00:45<00:00, 81.80it/s, loss=0.284]\n",
            "Epoch 6: 100%|██████████| 3750/3750 [00:46<00:00, 80.45it/s, loss=0.27]\n",
            "Epoch 7: 100%|██████████| 3750/3750 [00:46<00:00, 80.02it/s, loss=0.258]\n",
            "Epoch 8: 100%|██████████| 3750/3750 [00:47<00:00, 79.78it/s, loss=0.247]\n",
            "Epoch 9: 100%|██████████| 3750/3750 [00:45<00:00, 81.54it/s, loss=0.241]\n",
            "Epoch 10: 100%|██████████| 3750/3750 [00:46<00:00, 79.82it/s, loss=0.232]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ],
      "metadata": {
        "id": "kwa9abFu6Lv5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model: nn.Module, total_iterations: int = None):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    iterations = 0\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in tqdm(test_loader, desc='Testing'):\n",
        "            x, y = data\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            output = model(x.view(-1, 784))\n",
        "            for idx, i in enumerate(output):\n",
        "                if torch.argmax(i) == y[idx]:\n",
        "                    correct +=1\n",
        "                total +=1\n",
        "            iterations += 1\n",
        "            if total_iterations is not None and iterations >= total_iterations:\n",
        "                break\n",
        "    print(f'Accuracy: {round(correct/total, 3)}')"
      ],
      "metadata": {
        "id": "ZLxNcHAS6FqB"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZH5kfsg6dBn",
        "outputId": "23c5ae60-9f4d-4670-9540-8b71d033c8bd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 3750/3750 [00:18<00:00, 200.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.922\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Print weights and size of the model before quantization"
      ],
      "metadata": {
        "id": "QAkSN8nE6mad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the weights matrix of the model before quantization\n",
        "print('Weights before quantization')\n",
        "print(model.linear1.weight)\n",
        "print(model.linear1.weight.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAfEguGT6kw3",
        "outputId": "f56aa713-d2b2-4d4a-90da-3ebecb13a11a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights before quantization\n",
            "Parameter containing:\n",
            "tensor([[ 0.0755,  0.0828, -0.0091,  ...,  0.0536,  0.0798,  0.0720],\n",
            "        [-0.0101, -0.0183, -0.0618,  ..., -0.1195, -0.0224, -0.0202],\n",
            "        [ 0.0850,  0.1174,  0.0451,  ...,  0.0233,  0.0333,  0.0921],\n",
            "        ...,\n",
            "        [ 0.0236, -0.0083,  0.0074,  ..., -0.0738, -0.0481,  0.0258],\n",
            "        [ 0.1485,  0.1255,  0.0529,  ...,  0.1001,  0.1012,  0.1476],\n",
            "        [ 0.0257,  0.0074,  0.0256,  ...,  0.1097, -0.0216,  0.0140]],\n",
            "       requires_grad=True)\n",
            "torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_size_of_model(model):\n",
        "    torch.save(model.state_dict(), \"temp_delme.p\")\n",
        "    print('Size (KB):', os.path.getsize(\"temp_delme.p\")/1e3)\n",
        "    os.remove('temp_delme.p')"
      ],
      "metadata": {
        "id": "XdsROxaQ6tmg"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Size of the model before quantization')\n",
        "print_size_of_model(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohf1xCwe61fs",
        "outputId": "436fe474-c416-484b-b364-2eba1f65154c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of the model before quantization\n",
            "Size (KB): 546.918\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Accuracy of the model before quantization: ')\n",
        "test(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sx_-wxKP64aO",
        "outputId": "2c9c37f7-792a-4c25-9808-b474b1a8a798"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the model before quantization: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 3750/3750 [00:19<00:00, 191.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.922\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Insert min-max observers in the model"
      ],
      "metadata": {
        "id": "pgUefHI47I7f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class QuantizedFashionNet(nn.Module):\n",
        "    def __init__(self, hidden_size_1=128, hidden_size_2=256):\n",
        "        super(QuantizedFashionNet,self).__init__()\n",
        "        self.quant = torch.quantization.QuantStub()\n",
        "        self.linear1 = nn.Linear(28*28, hidden_size_1)\n",
        "        self.linear2 = nn.Linear(hidden_size_1, hidden_size_2)\n",
        "        self.linear3 = nn.Linear(hidden_size_2, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dequant = torch.quantization.DeQuantStub()\n",
        "\n",
        "    def forward(self, img):\n",
        "        x = img.view(-1, 28*28)\n",
        "        x = self.quant(x)\n",
        "        x = self.relu(self.linear1(x))\n",
        "        x = self.relu(self.linear2(x))\n",
        "        x = self.linear3(x)\n",
        "        x = self.dequant(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "Lk9C1SL9688l"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_quantized = QuantizedFashionNet().to(device)"
      ],
      "metadata": {
        "id": "RquFMBpJ7kZe"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy weights from unquantized model\n",
        "model_quantized.load_state_dict(model.state_dict())\n",
        "model_quantized.eval()\n",
        "\n",
        "model_quantized.qconfig = torch.ao.quantization.default_qconfig\n",
        "model_quantized = torch.ao.quantization.prepare(model_quantized) # Insert observers\n",
        "model_quantized"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7sMdJ0F7s3d",
        "outputId": "6247ea01-a8c2-4c88-c588-e13b6477a0b4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "QuantizedFashionNet(\n",
              "  (quant): QuantStub(\n",
              "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "  )\n",
              "  (linear1): Linear(\n",
              "    in_features=784, out_features=128, bias=True\n",
              "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "  )\n",
              "  (linear2): Linear(\n",
              "    in_features=128, out_features=256, bias=True\n",
              "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "  )\n",
              "  (linear3): Linear(\n",
              "    in_features=256, out_features=10, bias=True\n",
              "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "  )\n",
              "  (relu): ReLU()\n",
              "  (dequant): DeQuantStub()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calibrate the model using the test set"
      ],
      "metadata": {
        "id": "-t0VfCzz_wUW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test(model_quantized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9sTHGlV78Pv",
        "outputId": "0b46c367-8d3d-41c1-8cdb-d18e7116f956"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 3750/3750 [00:20<00:00, 187.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.922\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Check statistics of the various layers')\n",
        "model_quantized"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLJu_ZERAQir",
        "outputId": "512e8824-939c-419a-b570-987ba58f14a6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Check statistics of the various layers\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "QuantizedFashionNet(\n",
              "  (quant): QuantStub(\n",
              "    (activation_post_process): MinMaxObserver(min_val=-0.4242129623889923, max_val=2.821486711502075)\n",
              "  )\n",
              "  (linear1): Linear(\n",
              "    in_features=784, out_features=128, bias=True\n",
              "    (activation_post_process): MinMaxObserver(min_val=-119.12142944335938, max_val=73.69100189208984)\n",
              "  )\n",
              "  (linear2): Linear(\n",
              "    in_features=128, out_features=256, bias=True\n",
              "    (activation_post_process): MinMaxObserver(min_val=-106.03083038330078, max_val=78.91856384277344)\n",
              "  )\n",
              "  (linear3): Linear(\n",
              "    in_features=256, out_features=10, bias=True\n",
              "    (activation_post_process): MinMaxObserver(min_val=-263.02685546875, max_val=49.16145324707031)\n",
              "  )\n",
              "  (relu): ReLU()\n",
              "  (dequant): DeQuantStub()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quantize the model using the statistics collected"
      ],
      "metadata": {
        "id": "4Py0J-XqAazx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_quantized = torch.ao.quantization.convert(model_quantized)"
      ],
      "metadata": {
        "id": "nStaZriwAWVu"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Check statistics of the various layers')\n",
        "model_quantized"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7hCj3FdA5Eq",
        "outputId": "ec0c82a2-1bd4-4849-bc30-9090f6b7f422"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Check statistics of the various layers\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "QuantizedFashionNet(\n",
              "  (quant): Quantize(scale=tensor([0.0256]), zero_point=tensor([17]), dtype=torch.quint8)\n",
              "  (linear1): QuantizedLinear(in_features=784, out_features=128, scale=1.5182081460952759, zero_point=78, qscheme=torch.per_tensor_affine)\n",
              "  (linear2): QuantizedLinear(in_features=128, out_features=256, scale=1.4562945365905762, zero_point=73, qscheme=torch.per_tensor_affine)\n",
              "  (linear3): QuantizedLinear(in_features=256, out_features=10, scale=2.4581754207611084, zero_point=107, qscheme=torch.per_tensor_affine)\n",
              "  (relu): ReLU()\n",
              "  (dequant): DeQuantize()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the weights matrix of the model after quantization\n",
        "print('Weights after quantization')\n",
        "print(torch.int_repr(model_quantized.linear1.weight()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FU3BjFEsA-AU",
        "outputId": "1adec916-c0df-4b3d-8e42-3bfe689c5165"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights after quantization\n",
            "tensor([[ 5,  6, -1,  ...,  4,  5,  5],\n",
            "        [-1, -1, -4,  ..., -8, -2, -1],\n",
            "        [ 6,  8,  3,  ...,  2,  2,  6],\n",
            "        ...,\n",
            "        [ 2, -1,  0,  ..., -5, -3,  2],\n",
            "        [10,  8,  4,  ...,  7,  7, 10],\n",
            "        [ 2,  0,  2,  ...,  7, -1,  1]], dtype=torch.int8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compare the dequantized weights and the original weights"
      ],
      "metadata": {
        "id": "gSDhhoH5BkOa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Original weights: ')\n",
        "print(model.linear1.weight)\n",
        "print('')\n",
        "print(f'Dequantized weights: ')\n",
        "print(torch.dequantize(model_quantized.linear1.weight()))\n",
        "print('')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAP11du9Bfp1",
        "outputId": "b51766d1-bff0-4559-84c3-525b9ea966b1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original weights: \n",
            "Parameter containing:\n",
            "tensor([[ 0.0755,  0.0828, -0.0091,  ...,  0.0536,  0.0798,  0.0720],\n",
            "        [-0.0101, -0.0183, -0.0618,  ..., -0.1195, -0.0224, -0.0202],\n",
            "        [ 0.0850,  0.1174,  0.0451,  ...,  0.0233,  0.0333,  0.0921],\n",
            "        ...,\n",
            "        [ 0.0236, -0.0083,  0.0074,  ..., -0.0738, -0.0481,  0.0258],\n",
            "        [ 0.1485,  0.1255,  0.0529,  ...,  0.1001,  0.1012,  0.1476],\n",
            "        [ 0.0257,  0.0074,  0.0256,  ...,  0.1097, -0.0216,  0.0140]],\n",
            "       requires_grad=True)\n",
            "\n",
            "Dequantized weights: \n",
            "tensor([[ 0.0744,  0.0893, -0.0149,  ...,  0.0595,  0.0744,  0.0744],\n",
            "        [-0.0149, -0.0149, -0.0595,  ..., -0.1191, -0.0298, -0.0149],\n",
            "        [ 0.0893,  0.1191,  0.0447,  ...,  0.0298,  0.0298,  0.0893],\n",
            "        ...,\n",
            "        [ 0.0298, -0.0149,  0.0000,  ..., -0.0744, -0.0447,  0.0298],\n",
            "        [ 0.1489,  0.1191,  0.0595,  ...,  0.1042,  0.1042,  0.1489],\n",
            "        [ 0.0298,  0.0000,  0.0298,  ...,  0.1042, -0.0149,  0.0149]])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Print size and accuracy of the quantized model"
      ],
      "metadata": {
        "id": "szuApvnAB6th"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Size of the model after quantization')\n",
        "print_size_of_model(model_quantized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvmSDD_TBwoK",
        "outputId": "f22c621c-7280-45b6-fbe2-f7dce6415105"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of the model after quantization\n",
            "Size (KB): 142.498\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Testing the model after quantization')\n",
        "test(model_quantized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmIupl7RB-HX",
        "outputId": "9bb68702-1ff9-4a38-d31d-f6f9b35bb145"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing the model after quantization\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 3750/3750 [00:19<00:00, 191.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.901\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XM5mU4fsCBs7"
      },
      "execution_count": 24,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}