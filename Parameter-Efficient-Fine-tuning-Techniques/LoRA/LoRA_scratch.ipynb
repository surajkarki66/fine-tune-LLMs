{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptOcmopyW-U1"
      },
      "source": [
        "# LoRA from Scratch\n",
        "In this notebook, we are going to implement the LoRa fine tuning in a Pre-trained PyTorch model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifzOwybFW-U-"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WtkTLRrKW-VA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make the model deterministic"
      ],
      "metadata": {
        "id": "xM5kSiptYj-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make torch deterministic\n",
        "_ = torch.manual_seed(0)"
      ],
      "metadata": {
        "id": "mrC39SPyYlFS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zlea0GqHW-VF"
      },
      "source": [
        "## Dataset\n",
        "We will be training a network to classify FashionMNIST and then fine-tune the network on a particular class on which it doesn't perform well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZadocPRW-VI",
        "outputId": "9a5b4bfd-06cd-438d-9e56-f838e0d3ef61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:02<00:00, 11494270.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 208933.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:01<00:00, 3882853.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 17771421.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
        "\n",
        "# Load the FashionMNIST dataset\n",
        "fmnist_trainset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "# Create a dataloader for the training\n",
        "train_loader = torch.utils.data.DataLoader(fmnist_trainset, batch_size=16, shuffle=True)\n",
        "\n",
        "# Load the FashionMNIST test set\n",
        "fmnist_testset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(fmnist_testset, batch_size=16, shuffle=True)\n",
        "\n",
        "# Define the device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5zjIBr3W-VT"
      },
      "source": [
        "## Model Building\n",
        "Create the Neural Network to classify the fashion product, making it overly complicated to better show the power of LoRA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Bd9asV26W-VX"
      },
      "outputs": [],
      "source": [
        "# Create an overly expensive neural network to classify FashionMNIST\n",
        "class HeavyNet(nn.Module):\n",
        "    def __init__(self, hidden_size_1=1000, hidden_size_2=2000):\n",
        "        super(HeavyNet,self).__init__()\n",
        "        self.linear1 = nn.Linear(28*28, hidden_size_1)\n",
        "        self.linear2 = nn.Linear(hidden_size_1, hidden_size_2)\n",
        "        self.linear3 = nn.Linear(hidden_size_2, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, img):\n",
        "        x = img.view(-1, 28*28)\n",
        "        x = self.relu(self.linear1(x))\n",
        "        x = self.relu(self.linear2(x))\n",
        "        x = self.linear3(x)\n",
        "        return x\n",
        "\n",
        "model = HeavyNet().to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quSSSNJWW-Vb"
      },
      "source": [
        "Train the network only for 4 epoch to simulate a complete general pre-training on the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iq4VG2XyW-Ve",
        "outputId": "57e62e9c-3236-4d65-84b7-64a1159c5c97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 3750/3750 [00:38<00:00, 97.16it/s, loss=0.475] \n",
            "Epoch 2: 100%|██████████| 3750/3750 [00:43<00:00, 86.58it/s, loss=0.369]\n",
            "Epoch 3: 100%|██████████| 3750/3750 [00:37<00:00, 99.86it/s, loss=0.333]\n",
            "Epoch 4: 100%|██████████| 3750/3750 [00:38<00:00, 97.47it/s, loss=0.308] \n",
            "Epoch 5: 100%|██████████| 3750/3750 [00:37<00:00, 100.45it/s, loss=0.293]\n",
            "Epoch 6: 100%|██████████| 3750/3750 [00:37<00:00, 100.55it/s, loss=0.282]\n",
            "Epoch 7: 100%|██████████| 3750/3750 [00:36<00:00, 101.92it/s, loss=0.273]\n",
            "Epoch 8: 100%|██████████| 3750/3750 [00:37<00:00, 101.04it/s, loss=0.26]\n",
            "Epoch 9: 100%|██████████| 3750/3750 [00:37<00:00, 100.57it/s, loss=0.245]\n",
            "Epoch 10: 100%|██████████| 3750/3750 [00:37<00:00, 101.27it/s, loss=0.243]\n",
            "Epoch 11: 100%|██████████| 3750/3750 [00:36<00:00, 102.24it/s, loss=0.235]\n",
            "Epoch 12: 100%|██████████| 3750/3750 [00:36<00:00, 101.93it/s, loss=0.228]\n",
            "Epoch 13: 100%|██████████| 3750/3750 [00:36<00:00, 102.03it/s, loss=0.223]\n",
            "Epoch 14: 100%|██████████| 3750/3750 [00:37<00:00, 100.90it/s, loss=0.22]\n",
            "Epoch 15: 100%|██████████| 3750/3750 [00:37<00:00, 100.29it/s, loss=0.219]\n",
            "Epoch 16: 100%|██████████| 3750/3750 [00:37<00:00, 100.84it/s, loss=0.213]\n",
            "Epoch 17: 100%|██████████| 3750/3750 [00:36<00:00, 102.65it/s, loss=0.207]\n",
            "Epoch 18: 100%|██████████| 3750/3750 [00:36<00:00, 103.85it/s, loss=0.203]\n",
            "Epoch 19: 100%|██████████| 3750/3750 [00:36<00:00, 102.92it/s, loss=0.201]\n",
            "Epoch 20: 100%|██████████| 3750/3750 [00:37<00:00, 100.67it/s, loss=0.195]\n",
            "Epoch 21: 100%|██████████| 3750/3750 [00:37<00:00, 100.25it/s, loss=0.197]\n",
            "Epoch 22: 100%|██████████| 3750/3750 [00:37<00:00, 100.83it/s, loss=0.191]\n",
            "Epoch 23: 100%|██████████| 3750/3750 [00:37<00:00, 100.73it/s, loss=0.187]\n",
            "Epoch 24: 100%|██████████| 3750/3750 [00:37<00:00, 100.27it/s, loss=0.184]\n",
            "Epoch 25: 100%|██████████| 3750/3750 [00:37<00:00, 100.78it/s, loss=0.185]\n",
            "Epoch 26: 100%|██████████| 3750/3750 [00:36<00:00, 101.96it/s, loss=0.18]\n",
            "Epoch 27: 100%|██████████| 3750/3750 [00:37<00:00, 100.82it/s, loss=0.18]\n",
            "Epoch 28: 100%|██████████| 3750/3750 [00:37<00:00, 100.72it/s, loss=0.177]\n",
            "Epoch 29: 100%|██████████| 3750/3750 [00:37<00:00, 100.75it/s, loss=0.173]\n",
            "Epoch 30: 100%|██████████| 3750/3750 [00:37<00:00, 100.79it/s, loss=0.169]\n",
            "Epoch 31: 100%|██████████| 3750/3750 [00:37<00:00, 100.50it/s, loss=0.168]\n",
            "Epoch 32: 100%|██████████| 3750/3750 [00:37<00:00, 101.14it/s, loss=0.172]\n",
            "Epoch 33: 100%|██████████| 3750/3750 [00:37<00:00, 100.78it/s, loss=0.17]\n",
            "Epoch 34: 100%|██████████| 3750/3750 [00:36<00:00, 102.03it/s, loss=0.169]\n",
            "Epoch 35: 100%|██████████| 3750/3750 [00:36<00:00, 102.04it/s, loss=0.164]\n",
            "Epoch 36: 100%|██████████| 3750/3750 [00:36<00:00, 101.88it/s, loss=0.161]\n",
            "Epoch 37: 100%|██████████| 3750/3750 [00:36<00:00, 101.87it/s, loss=0.165]\n",
            "Epoch 38: 100%|██████████| 3750/3750 [00:36<00:00, 101.58it/s, loss=0.157]\n",
            "Epoch 39: 100%|██████████| 3750/3750 [00:36<00:00, 102.60it/s, loss=0.161]\n",
            "Epoch 40: 100%|██████████| 3750/3750 [00:36<00:00, 102.17it/s, loss=0.157]\n"
          ]
        }
      ],
      "source": [
        "def train(train_loader, net, epochs=5, total_iterations_limit=None):\n",
        "    cross_el = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
        "\n",
        "    total_iterations = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        net.train()\n",
        "\n",
        "        loss_sum = 0\n",
        "        num_iterations = 0\n",
        "\n",
        "        data_iterator = tqdm(train_loader, desc=f'Epoch {epoch+1}')\n",
        "        if total_iterations_limit is not None:\n",
        "            data_iterator.total = total_iterations_limit\n",
        "        for data in data_iterator:\n",
        "            num_iterations += 1\n",
        "            total_iterations += 1\n",
        "            x, y = data\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = net(x.view(-1, 28*28))\n",
        "            loss = cross_el(output, y)\n",
        "            loss_sum += loss.item()\n",
        "            avg_loss = loss_sum / num_iterations\n",
        "            data_iterator.set_postfix(loss=avg_loss)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if total_iterations_limit is not None and total_iterations >= total_iterations_limit:\n",
        "                return\n",
        "\n",
        "train(train_loader, model, epochs=40)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keep a copy of the original weights (cloning them) so later we can prove that a fine-tuning with LoRA doesn't alter the original weights"
      ],
      "metadata": {
        "id": "UQIk_rBobLdf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-yfdPnx6W-Vf"
      },
      "outputs": [],
      "source": [
        "original_weights = {}\n",
        "for name, param in model.named_parameters():\n",
        "    original_weights[name] = param.clone().detach()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(original_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0YqeEX9bjLo",
        "outputId": "be5bf5fd-83c8-415d-aa93-1cc72cc852c1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'linear1.weight': tensor([[ 0.1223,  0.1458,  0.0794,  ...,  0.1505,  0.1159,  0.0941],\n",
            "        [ 0.2599,  0.2648,  0.2694,  ...,  0.1045,  0.1344,  0.2050],\n",
            "        [-0.2794, -0.2387, -0.2705,  ..., -0.1876, -0.0399, -0.2510],\n",
            "        ...,\n",
            "        [ 0.0669,  0.1504,  0.0941,  ..., -0.0678, -0.0242,  0.0169],\n",
            "        [ 0.2425,  0.2048,  0.1815,  ...,  0.0613,  0.1004,  0.1938],\n",
            "        [ 0.2224,  0.1993,  0.3989,  ...,  0.3100,  0.4096,  0.4887]],\n",
            "       device='cuda:0'), 'linear1.bias': tensor([-1.4711e-01, -2.5835e-01,  2.6955e-01, -3.0588e-01, -3.0351e-01,\n",
            "        -2.1274e-01, -1.9532e-01, -2.3322e-01, -3.0170e-01, -3.2989e-01,\n",
            "        -4.2280e-01, -2.9504e-01, -1.6234e-01, -3.6246e-01, -2.8369e-01,\n",
            "        -2.7464e-01, -2.4800e-01, -2.6639e-01, -2.1724e-01, -2.7043e-01,\n",
            "        -2.3653e-01, -2.8108e-01, -6.6564e-02, -3.5127e-01, -1.7921e-01,\n",
            "        -2.3703e-01, -2.8320e-01, -2.1528e-01, -2.8924e-01, -2.8332e-01,\n",
            "        -3.7025e-01, -3.4820e-01, -2.1242e-01, -2.1207e-01, -3.4194e-01,\n",
            "        -9.7877e-02, -2.7375e-01, -2.0963e-01, -2.7580e-01, -1.5815e-01,\n",
            "        -2.2332e-01, -2.8030e-01, -3.2103e-01, -3.5424e-01, -1.3815e-01,\n",
            "        -4.7025e-01, -3.7034e-01, -2.7576e-01, -2.5848e-01, -3.2204e-01,\n",
            "        -9.7003e-02, -4.6822e-01, -2.0309e-01, -2.1959e-01, -2.1879e-01,\n",
            "        -2.5139e-01, -2.2236e-01, -2.2116e-01, -1.8782e-01, -1.8807e-01,\n",
            "        -2.8148e-01, -1.0104e-01, -1.6645e-01, -1.4728e-01, -1.8148e-01,\n",
            "        -2.4192e-01, -2.2133e-01, -1.5809e-01, -7.6201e-02, -2.3331e-01,\n",
            "         3.9681e-01, -1.5963e-01, -2.8061e-01, -1.2020e-01, -3.9379e-01,\n",
            "        -3.6453e-01, -1.9104e-01, -2.3370e-01, -3.5564e-01, -1.6400e-01,\n",
            "        -3.5573e-01, -3.7521e-01, -1.7579e-01, -2.3980e-01,  4.0586e-01,\n",
            "        -2.3447e-01, -3.2606e-01, -2.7091e-01, -3.0316e-01, -2.7611e-01,\n",
            "        -2.5535e-01, -2.7563e-01, -1.3199e-01, -1.8969e-01, -3.5459e-01,\n",
            "        -1.6326e-01, -1.3821e-01, -2.1585e-01, -1.5384e-01, -2.3487e-01,\n",
            "        -2.2247e-01, -2.0796e-01, -2.2345e-01, -2.3895e-01, -1.8120e-01,\n",
            "        -1.0841e-01, -2.3652e-01, -3.1202e-01, -3.5429e-01, -1.8284e-01,\n",
            "        -1.8222e-01, -3.7614e-01, -3.3137e-01, -3.6489e-01, -2.0489e-01,\n",
            "        -1.6227e-01, -1.7597e-01, -2.0735e-01, -2.1557e-01, -2.6079e-01,\n",
            "        -2.5636e-01, -2.6122e-01, -1.3393e-02, -2.5678e-01, -1.3841e-01,\n",
            "        -2.8914e-01, -1.4621e-01, -2.5736e-01, -5.0526e-01, -2.5893e-01,\n",
            "        -2.2182e-01, -2.1305e-01, -2.6641e-01, -1.9955e-01, -2.1481e-01,\n",
            "        -2.1916e-01, -2.3627e-01, -1.7024e-01, -2.0614e-01, -3.2977e-01,\n",
            "        -2.6915e-01, -3.3403e-01, -2.9488e-01, -1.6600e-01,  7.3628e-02,\n",
            "        -2.6540e-01, -2.3492e-01, -2.2555e-01, -3.2101e-01, -3.0593e-01,\n",
            "        -1.0154e-01, -2.5198e-01, -2.8748e-01, -2.9418e-01, -2.0265e-01,\n",
            "        -1.9969e-01, -2.9876e-01, -2.0088e-01, -1.3961e-01, -3.5670e-01,\n",
            "        -3.5751e-02, -2.7914e-01, -1.2201e-01, -2.7709e-01, -2.8520e-01,\n",
            "        -3.6020e-01, -2.4206e-01, -2.6505e-01, -1.0217e-01, -2.4191e-01,\n",
            "        -1.9074e-01, -3.6691e-01, -2.2323e-01, -2.9284e-01, -2.7588e-01,\n",
            "        -4.7083e-01, -2.8219e-01, -2.0849e-01, -3.4631e-01, -2.7326e-01,\n",
            "        -2.6770e-01, -2.8542e-01, -3.4115e-01, -2.8383e-01, -1.1742e-01,\n",
            "        -2.7396e-01, -2.3758e-01, -4.4028e-01, -2.0455e-01, -2.8881e-01,\n",
            "        -1.5590e-01, -2.2540e-01, -3.3078e-01, -2.0780e-01, -1.8205e-01,\n",
            "        -2.0815e-01, -2.5154e-01, -1.6880e-01, -1.8714e-01, -2.6914e-01,\n",
            "        -8.8836e-02, -1.6650e-01, -2.3274e-01, -2.0511e-01, -3.5336e-01,\n",
            "        -1.7709e-01, -3.3957e-01, -2.5919e-01, -3.1838e-01, -3.0245e-01,\n",
            "        -3.3133e-01, -3.2318e-01, -2.8822e-01, -1.9264e-01, -2.2411e-01,\n",
            "        -2.3852e-01, -2.0651e-01, -4.0435e-02, -3.1478e-01, -4.0374e-01,\n",
            "        -2.6188e-01, -2.8403e-01, -8.8032e-02, -3.1490e-01, -3.4933e-01,\n",
            "        -3.1095e-01, -3.8449e-01, -2.6852e-01, -5.4026e-02, -3.0379e-01,\n",
            "        -2.0207e-01, -2.3003e-01, -4.7395e-01, -3.0510e-01, -2.0571e-01,\n",
            "        -9.8829e-02, -3.2785e-01, -1.2951e-01, -2.5850e-01, -2.7157e-02,\n",
            "        -3.3275e-01, -2.0948e-01, -2.7782e-02, -1.8876e-01, -1.5123e-01,\n",
            "        -3.7524e-01, -2.4442e-01, -3.0109e-01, -4.3314e-01, -2.6794e-01,\n",
            "        -3.0119e-01, -2.5798e-01, -1.4715e-01, -2.5100e-01, -2.4687e-01,\n",
            "        -1.3282e-01, -2.3094e-01, -1.7515e-01, -2.4091e-01, -3.1291e-01,\n",
            "        -2.7310e-01, -2.6608e-01, -2.3298e-01, -2.8231e-01, -1.4709e-01,\n",
            "        -2.3573e-01, -4.3525e-02, -1.0192e-01, -2.4210e-01, -1.9776e-01,\n",
            "        -3.4323e-01, -2.0836e-01, -3.7825e-01, -2.8738e-01, -5.5848e-01,\n",
            "        -1.3584e-01, -7.6045e-02, -1.5662e-01,  6.4372e-02, -4.5396e-01,\n",
            "        -3.1592e-01, -2.4861e-01, -2.8224e-01, -1.2097e-01, -9.8753e-02,\n",
            "        -1.0378e-01, -2.3113e-01, -3.4385e-01, -2.8901e-01, -3.8049e-01,\n",
            "        -1.5301e-01, -2.9779e-01, -3.0942e-01, -4.1314e-01, -2.2591e-01,\n",
            "        -1.7392e-01, -1.3608e-01, -1.6514e-01, -2.1010e-01, -2.9955e-01,\n",
            "        -2.8100e-01, -2.9024e-01, -2.2283e-01, -2.5329e-01, -3.5740e-01,\n",
            "        -1.5091e-01, -1.5262e-01, -2.0478e-01, -2.5487e-01, -2.4459e-01,\n",
            "        -3.4634e-01, -1.2565e-01, -2.1526e-01, -2.4416e-01, -1.0891e-01,\n",
            "        -2.0145e-01, -2.3411e-01, -2.0709e-01, -2.5212e-01, -2.6898e-01,\n",
            "        -2.6161e-01, -4.2251e-01, -2.8339e-01, -3.8605e-01, -3.3079e-01,\n",
            "        -1.3256e-01, -9.2116e-02, -2.2262e-01, -2.2142e-01, -3.3648e-01,\n",
            "         6.7488e-02, -1.3597e-01, -2.7206e-01, -2.2640e-01, -1.0922e-01,\n",
            "        -2.7434e-01, -2.3419e-01, -1.8576e-01, -2.9842e-01, -2.6619e-01,\n",
            "        -1.7283e-01, -2.7526e-01, -2.6966e-01, -1.0715e-01, -2.7907e-01,\n",
            "        -1.7297e-02, -2.9821e-01, -2.2393e-01, -2.0818e-01, -7.4792e-02,\n",
            "        -1.6251e-01, -1.4461e-01, -1.2973e-01, -7.4474e-02, -3.5225e-01,\n",
            "        -9.5807e-02, -1.9015e-01, -3.0534e-01, -7.8030e-02, -2.1304e-01,\n",
            "        -2.2048e-01, -2.4182e-01, -1.7558e-01, -2.4573e-01, -3.6264e-01,\n",
            "        -3.1204e-01, -2.8136e-01, -4.5465e-02, -2.4639e-01, -2.6706e-01,\n",
            "        -1.7752e-01, -2.5249e-01, -2.8419e-01, -2.2048e-01, -1.7978e-01,\n",
            "        -1.5452e-01, -3.1277e-02, -2.6694e-01,  1.7173e-01, -1.1112e-01,\n",
            "        -1.5816e-01, -2.4473e-01, -2.2222e-01, -3.4472e-01, -1.8828e-01,\n",
            "        -2.3081e-01, -3.9519e-01, -2.9306e-01, -2.3597e-01, -2.1006e-01,\n",
            "        -2.9959e-01, -1.9629e-01, -2.8577e-01, -1.1113e-01, -1.7624e-01,\n",
            "        -2.0752e-01, -1.6415e-01, -2.4216e-01, -2.5307e-01, -1.3091e-01,\n",
            "        -1.7646e-01, -5.8728e-02, -3.0188e-01, -2.2611e-01, -2.2703e-01,\n",
            "        -2.4131e-01, -2.5787e-01, -2.0176e-01, -1.6718e-01, -2.2273e-01,\n",
            "        -5.8255e-02, -1.0357e-01, -2.1879e-01, -3.6793e-01, -7.9687e-02,\n",
            "        -1.7158e-01, -3.0214e-01, -1.6269e-01, -3.9650e-01, -3.0817e-01,\n",
            "        -3.2099e-01, -2.2113e-01, -1.5821e-01, -1.9976e-01, -3.9228e-01,\n",
            "        -2.0312e-01, -1.9048e-01, -1.8323e-01, -2.8180e-01, -3.0744e-01,\n",
            "        -3.3506e-01, -2.4425e-01, -2.8324e-01, -3.3123e-01, -2.3957e-01,\n",
            "        -1.8381e-01, -3.4806e-01, -2.3471e-01, -2.9285e-01, -2.8623e-01,\n",
            "        -2.8666e-01, -1.8314e-01, -3.1940e-01, -3.3385e-01, -2.7183e-01,\n",
            "        -1.9508e-01, -3.3801e-01, -2.5578e-01, -1.8798e-01, -2.2999e-01,\n",
            "        -1.1219e-01, -3.2528e-01, -1.7530e-01, -2.1947e-01, -3.4075e-01,\n",
            "        -1.5789e-01, -1.6509e-01, -2.5174e-01, -1.8001e-01, -1.6422e-01,\n",
            "        -2.4415e-01, -2.7862e-01, -2.2681e-01, -2.0104e-01, -2.9768e-01,\n",
            "        -3.0494e-01, -3.1353e-01, -1.0790e-01, -3.7529e-01, -4.1622e-01,\n",
            "        -2.4244e-01, -1.9926e-01, -2.3152e-01, -3.1369e-01, -2.5019e-01,\n",
            "        -2.5971e-01, -1.9316e-01, -2.0743e-01, -2.0756e-01, -1.4312e-01,\n",
            "        -2.8643e-01, -4.7007e-01, -2.7018e-01, -3.3606e-01, -1.6052e-01,\n",
            "        -1.3015e-01, -1.7072e-01, -3.0314e-01, -1.8456e-01, -2.6037e-01,\n",
            "        -2.7273e-01, -2.1684e-01, -2.6546e-01, -1.6312e-01, -3.7218e-01,\n",
            "        -2.2513e-01, -2.9420e-01, -2.8029e-01, -1.6347e-01, -1.9168e-01,\n",
            "        -2.1412e-01, -2.3420e-01, -3.6971e-01, -1.0867e-01, -1.4077e-01,\n",
            "        -1.0217e-01, -2.4130e-01, -1.2408e-01, -2.4917e-01, -3.1576e-01,\n",
            "        -2.5653e-01, -2.4445e-01, -2.8827e-01, -1.7899e-01, -1.5493e-01,\n",
            "        -3.8099e-01, -1.6934e-01, -3.0311e-01, -8.0442e-02, -2.0886e-01,\n",
            "        -1.9814e-01, -4.2788e-01, -1.5636e-01, -3.7004e-01, -3.3560e-01,\n",
            "        -2.3051e-01, -2.3402e-01, -1.7848e-01, -3.0269e-01, -3.1375e-01,\n",
            "        -2.6100e-01, -2.4388e-01, -2.6920e-01, -1.8924e-01, -3.9332e-01,\n",
            "        -1.7381e-01, -2.0619e-01, -2.1030e-01, -2.6774e-01, -4.2249e-01,\n",
            "        -2.0285e-01, -2.1550e-01, -4.1226e-01, -2.4245e-01, -3.0677e-01,\n",
            "        -1.1159e-03, -7.0790e-02, -2.1544e-01, -7.8507e-02, -1.6818e-01,\n",
            "        -1.8046e-01, -3.0246e-01, -8.2047e-02, -1.5874e-01, -1.7677e-01,\n",
            "        -1.5823e-01, -2.4047e-01, -4.9912e-01, -4.2185e-01, -3.5436e-01,\n",
            "        -2.0990e-01, -1.7731e-01, -1.3172e-01, -2.3799e-01, -1.4879e-01,\n",
            "        -3.2482e-01, -3.2378e-01, -3.1052e-01, -1.1417e-01, -2.0075e-01,\n",
            "        -3.3489e-01, -1.6645e-01, -2.2969e-01, -2.3402e-01, -2.8756e-01,\n",
            "        -2.8883e-01, -3.4214e-01, -1.9333e-01, -2.7132e-01, -3.7452e-01,\n",
            "        -3.2937e-01, -3.6865e-01, -1.6147e-01, -3.0393e-01, -3.0644e-01,\n",
            "        -1.9112e-01, -2.2504e-01, -2.4747e-01, -2.5976e-01, -4.5809e-02,\n",
            "        -2.9314e-01, -2.7742e-01, -2.8188e-01, -2.3996e-01, -2.5744e-01,\n",
            "        -2.2774e-01, -1.7008e-01, -2.6434e-01, -1.9072e-01, -2.8483e-01,\n",
            "        -5.8856e-01, -3.1967e-01, -8.9741e-02, -2.0545e-01, -2.8317e-01,\n",
            "        -7.4361e-02, -1.4826e-01, -2.5585e-01, -1.6604e-01, -2.5401e-01,\n",
            "        -1.0808e-01, -3.6883e-02, -7.6068e-02, -4.5383e-01, -2.0836e-01,\n",
            "        -3.0037e-01, -3.8534e-01, -2.2794e-01, -2.2697e-01, -4.0573e-01,\n",
            "        -1.1437e-01, -3.0921e-01, -2.5677e-01, -1.9000e-01, -1.3465e-01,\n",
            "        -1.9249e-01, -2.4922e-01, -2.3461e-01, -2.7238e-01, -2.1151e-01,\n",
            "        -1.3630e-01, -1.9285e-01, -1.9153e-01, -2.1420e-01, -1.7850e-01,\n",
            "        -2.4393e-01, -2.4417e-01, -4.0104e-01, -1.7197e-01, -2.7262e-01,\n",
            "        -1.9258e-01, -6.2554e-02, -9.3189e-02, -2.2216e-01, -1.3252e-01,\n",
            "        -3.1679e-01, -3.7409e-01, -2.1568e-01, -1.3544e-01, -2.5048e-01,\n",
            "        -1.8330e-01, -2.6255e-01, -2.1119e-01, -2.8239e-01, -1.7815e-01,\n",
            "        -2.2135e-01, -1.0352e-01, -2.9210e-01, -7.8483e-02, -2.3803e-01,\n",
            "        -2.8069e-01, -2.6260e-01, -3.4761e-01, -2.9333e-01, -3.3645e-01,\n",
            "        -5.7670e-02, -1.3676e-01, -3.2394e-01, -1.2967e-01, -2.6446e-01,\n",
            "        -3.3186e-01, -2.5829e-01, -2.9455e-01, -2.2660e-01, -3.1525e-01,\n",
            "        -2.5950e-01, -2.5571e-01, -2.4810e-01, -2.6970e-01, -2.6266e-01,\n",
            "        -3.3234e-01, -2.1290e-01, -2.1776e-01, -1.7391e-01, -3.2496e-01,\n",
            "        -2.7314e-01, -2.0710e-01, -1.2554e-01, -8.6924e-02, -2.4201e-01,\n",
            "        -2.9856e-01, -2.3063e-01, -3.2390e-01, -1.0947e-01, -2.3884e-01,\n",
            "        -3.6592e-01, -1.7791e-01, -2.1426e-01, -2.0227e-01, -2.9455e-01,\n",
            "        -1.7090e-01, -9.9397e-02, -2.7340e-01, -3.6820e-01, -1.4299e-01,\n",
            "        -2.0495e-01, -2.2124e-01, -3.6938e-01, -3.6349e-01, -1.9550e-01,\n",
            "        -2.7177e-01, -2.9666e-01, -2.0949e-01, -2.4552e-01, -8.7958e-02,\n",
            "        -3.3150e-01, -2.3274e-01, -1.3997e-01, -2.0730e-01,  1.0641e+00,\n",
            "        -4.4093e-01, -2.3074e-01, -1.1966e-01, -3.7832e-01, -3.8008e-01,\n",
            "        -2.9373e-01, -2.3764e-01, -2.3354e-01, -4.2129e-01, -1.7960e-01,\n",
            "        -1.8724e-01, -2.3976e-01, -2.9446e-01,  4.5980e-01, -1.8613e-01,\n",
            "        -4.3696e-01, -4.2049e-01, -3.3642e-01, -2.1851e-01, -3.7289e-01,\n",
            "        -1.9691e-01, -2.2877e-01, -2.7675e-01, -2.5554e-01, -2.4799e-01,\n",
            "        -9.1804e-02, -2.3947e-01, -2.0085e-01, -2.5311e-01, -2.4686e-01,\n",
            "        -2.4166e-01, -1.0852e-01, -2.3295e-01, -1.1736e-01, -1.9013e-01,\n",
            "        -2.6754e-01, -2.2884e-01, -2.6792e-01, -1.2924e-01, -2.9175e-01,\n",
            "        -3.3544e-01, -2.3846e-01, -2.9686e-01, -1.2145e-01, -1.9478e-01,\n",
            "        -1.7129e-01, -2.4173e-01, -2.5621e-01, -1.9523e-01, -1.6500e-01,\n",
            "        -3.1510e-01, -3.4753e-01, -2.3001e-01, -2.3193e-01,  1.7572e-01,\n",
            "        -3.8495e-01, -3.5777e-01, -1.3300e-01, -2.9701e-01, -2.6289e-01,\n",
            "        -9.8536e-02, -2.2166e-01, -3.3159e-01, -2.0308e-01, -2.5548e-01,\n",
            "        -2.7119e-01, -9.6369e-02, -2.2895e-01, -2.1869e-02, -1.1909e-01,\n",
            "        -3.1672e-01, -1.9409e-01, -1.2307e-01, -1.9848e-01, -3.0537e-01,\n",
            "        -2.5345e-01, -2.3096e-01, -1.4513e-01, -1.3205e-01, -3.3847e-01,\n",
            "        -2.7596e-01,  8.5083e-02, -2.8851e-01, -2.3122e-01, -2.7594e-01,\n",
            "        -2.3834e-02, -2.6011e-01, -2.9091e-01, -3.9845e-01, -2.5270e-01,\n",
            "        -2.5414e-01, -3.2446e-01, -6.1795e-02, -3.0720e-01, -2.2266e-01,\n",
            "        -5.8302e-02, -2.9123e-01, -2.1124e-01, -2.2612e-01, -1.6254e-01,\n",
            "        -2.2322e-01,  1.6922e-02, -2.1856e-01, -2.3094e-01, -2.1367e-01,\n",
            "        -1.0841e-01, -2.0453e-01, -2.3029e-01, -3.4308e-01, -2.2501e-01,\n",
            "        -2.3106e-01, -3.4347e-01, -1.2491e-01, -2.5036e-01, -2.3136e-01,\n",
            "        -6.5267e-02, -2.3801e-01, -2.9540e-01, -1.5744e-01, -1.4378e-01,\n",
            "        -2.1945e-01, -1.9490e-01, -3.2126e-01, -2.2400e-01, -1.4864e-01,\n",
            "        -1.4435e-01, -1.6729e-01, -2.3573e-01, -2.5548e-01, -2.4651e-01,\n",
            "        -1.9480e-01, -2.7809e-01, -2.5853e-01, -3.0344e-01, -1.9532e-01,\n",
            "        -1.7187e-01, -3.4971e-01, -2.2923e-01, -1.5423e-01, -3.0013e-01,\n",
            "        -3.1411e-01,  1.0377e-01, -2.5663e-01, -1.6788e-01, -3.2606e-01,\n",
            "        -3.1710e-01, -1.8852e-01, -3.4354e-01, -1.9291e-01, -2.3355e-01,\n",
            "        -2.4810e-01, -1.7356e-01, -1.9302e-01, -3.2007e-01, -3.3738e-01,\n",
            "        -1.5957e-01, -3.3856e-01, -2.8333e-01, -4.5634e-01, -2.8947e-01,\n",
            "        -5.1602e-02, -2.6137e-01, -1.5528e-01, -2.9037e-01, -2.2146e-01,\n",
            "        -3.6002e-01, -4.0691e-01, -1.9815e-01, -1.4506e-01, -7.6419e-02,\n",
            "        -3.3891e-01, -1.1532e-02, -2.6929e-01, -2.5857e-01, -1.9546e-01,\n",
            "        -2.1721e-01, -1.3048e-01, -3.3877e-01, -2.3855e-01, -2.8914e-01,\n",
            "        -3.4773e-01, -3.4821e-01, -2.0540e-01, -2.7076e-01, -2.6493e-01,\n",
            "        -1.6103e-01, -1.8312e-01, -1.2956e-01, -2.3659e-01, -2.7632e-01,\n",
            "        -3.0431e-01, -4.1493e-01, -2.5388e-01,  7.4033e-02, -2.5534e-01,\n",
            "        -1.3787e-01, -2.7597e-01, -2.1526e-01, -2.0485e-01, -1.4243e-01,\n",
            "        -1.5017e-01, -1.0610e-01,  1.3438e-01, -1.9615e-01, -1.0942e-01,\n",
            "        -2.5448e-01, -3.0329e-01, -1.8980e-01, -1.3309e-01, -3.0358e-01,\n",
            "        -2.1308e-01, -2.7086e-01, -2.7606e-01, -3.2038e-01, -1.9523e-01,\n",
            "        -1.5448e-01, -2.9819e-01, -2.4656e-01, -2.5914e-01, -3.0649e-01,\n",
            "        -1.8562e-01, -3.1846e-01, -1.2401e-01, -1.2982e-01, -1.5088e-01,\n",
            "        -2.0749e-01, -3.4893e-01, -2.7125e-01, -3.9385e-01, -1.8326e-01,\n",
            "        -2.2448e-01, -2.7953e-01, -2.5129e-01, -1.9895e-01, -1.1963e-01,\n",
            "        -6.8380e-02, -2.5705e-01, -1.5297e-01, -2.8312e-01, -2.5224e-01,\n",
            "        -1.4689e-01, -2.2594e-01, -1.2355e-01, -2.7369e-01, -2.3711e-01,\n",
            "        -3.6794e-01, -2.0809e-01, -4.1909e-01, -8.6366e-02, -3.1233e-01,\n",
            "        -2.4630e-01, -2.0062e-01, -2.2760e-01, -8.9518e-02, -2.4306e-01,\n",
            "        -2.3191e-01, -3.1071e-01, -3.2472e-01, -2.7649e-01, -2.1370e-01,\n",
            "        -2.5392e-01, -3.1566e-03, -2.5048e-01, -3.4505e-01, -2.2119e-01,\n",
            "         1.1323e+00, -3.2611e-01, -2.3940e-01, -1.4727e-01, -7.4153e-02,\n",
            "        -1.6679e-01, -4.1400e-01, -3.7153e-01, -1.6435e-01, -2.3257e-01,\n",
            "        -3.3979e-01, -2.6966e-01, -7.6756e-02, -2.1665e-01, -2.2318e-01],\n",
            "       device='cuda:0'), 'linear2.weight': tensor([[-0.0210, -0.0019, -0.1873,  ...,  0.0057, -0.0311, -0.0070],\n",
            "        [-0.0395,  0.0151, -0.1056,  ...,  0.0312,  0.0232, -0.0553],\n",
            "        [-0.0155,  0.0206, -0.0536,  ..., -0.0055,  0.0222, -0.0106],\n",
            "        ...,\n",
            "        [ 0.0337,  0.0115, -0.0363,  ..., -0.0386,  0.0005,  0.0453],\n",
            "        [-0.0166, -0.0068, -0.0521,  ..., -0.0273, -0.0436, -0.0203],\n",
            "        [-0.0137,  0.0142, -0.0351,  ..., -0.0559,  0.0342, -0.0176]],\n",
            "       device='cuda:0'), 'linear2.bias': tensor([-0.1091, -0.0738, -0.0445,  ..., -0.1030, -0.0782, -0.0475],\n",
            "       device='cuda:0'), 'linear3.weight': tensor([[-1.1304e-01, -1.4203e-02,  2.1607e-02,  ...,  3.2680e-02,\n",
            "         -3.1300e-02,  4.3923e-03],\n",
            "        [ 4.8285e-02, -3.5087e-03, -5.9659e-03,  ...,  6.6499e-02,\n",
            "          1.2611e-02, -9.3967e-03],\n",
            "        [-2.9461e-02, -2.7868e-02,  1.3991e-03,  ..., -2.8249e-02,\n",
            "         -3.6728e-02, -2.8026e-02],\n",
            "        ...,\n",
            "        [-7.9930e-02, -5.6671e-03, -2.0599e-02,  ..., -8.7307e-02,\n",
            "         -3.5324e-02, -1.5240e-05],\n",
            "        [-3.4659e-02, -8.8636e-02, -8.6912e-03,  ..., -5.4697e-03,\n",
            "         -2.0215e-02,  5.7097e-03],\n",
            "        [-5.4675e-02,  4.2669e-02,  1.1395e-02,  ..., -1.3961e-01,\n",
            "          1.1737e-02,  4.0602e-03]], device='cuda:0'), 'linear3.bias': tensor([-0.1687, -0.7367,  0.2459,  0.2866, -0.1867,  0.2090, -0.0690,  0.0062,\n",
            "         0.4898, -0.3493], device='cuda:0')}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The the performance of the pretrained network."
      ],
      "metadata": {
        "id": "FloBpR6lbn3u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3QHGwH5W-Vi",
        "outputId": "c84e7eb4-11fd-450a-8614-e71469960988"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 625/625 [00:03<00:00, 163.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.886\n",
            "wrong counts for the class 0: 156\n",
            "wrong counts for the class 1: 17\n",
            "wrong counts for the class 2: 158\n",
            "wrong counts for the class 3: 132\n",
            "wrong counts for the class 4: 200\n",
            "wrong counts for the class 5: 22\n",
            "wrong counts for the class 6: 348\n",
            "wrong counts for the class 7: 40\n",
            "wrong counts for the class 8: 37\n",
            "wrong counts for the class 9: 34\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "def test():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    wrong_counts = [0 for i in range(10)]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in tqdm(test_loader, desc='Testing'):\n",
        "            x, y = data\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            output = model(x.view(-1, 784))\n",
        "            for idx, i in enumerate(output):\n",
        "                if torch.argmax(i) == y[idx]:\n",
        "                    correct +=1\n",
        "                else:\n",
        "                    wrong_counts[y[idx]] +=1\n",
        "                total +=1\n",
        "    print(f'Accuracy: {round(correct/total, 3)}')\n",
        "    for i in range(len(wrong_counts)):\n",
        "        print(f'wrong counts for the class {i}: {wrong_counts[i]}')\n",
        "\n",
        "test()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, the network performs poorly on the class 6. Let's fine-tune it on the class 6"
      ],
      "metadata": {
        "id": "oZWMTQDygmia"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's visualize how many parameters are in the original network, before introducing the LoRA matrices."
      ],
      "metadata": {
        "id": "DxWFYr3ZcGk-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rl-Zw6ijW-Vi",
        "outputId": "7ef35674-5f58-4e89-d29c-1cecc8bd8550"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer 1: W: torch.Size([1000, 784]) + B: torch.Size([1000])\n",
            "Layer 2: W: torch.Size([2000, 1000]) + B: torch.Size([2000])\n",
            "Layer 3: W: torch.Size([10, 2000]) + B: torch.Size([10])\n",
            "Total number of parameters: 2,807,010\n"
          ]
        }
      ],
      "source": [
        "# Print the size of the weights matrices of the network\n",
        "# Save the count of the total number of parameters\n",
        "total_parameters_original = 0\n",
        "for index, layer in enumerate([model.linear1, model.linear2, model.linear3]):\n",
        "    total_parameters_original += layer.weight.nelement() + layer.bias.nelement()\n",
        "    print(f'Layer {index+1}: W: {layer.weight.shape} + B: {layer.bias.shape}')\n",
        "print(f'Total number of parameters: {total_parameters_original:,}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LphUtxtoW-Vj"
      },
      "source": [
        "## Implementing LoRA\n",
        "Define the LoRA parameterization as described in the paper.\n",
        "The full detail on how PyTorch parameterizations work is here: https://pytorch.org/tutorials/intermediate/parametrizations.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "dIOpyBZOW-Vk"
      },
      "outputs": [],
      "source": [
        "class LoRAParametrization(nn.Module):\n",
        "    def __init__(self, features_in, features_out, rank=1, alpha=1, device='cpu'):\n",
        "        super().__init__()\n",
        "        # Section 4.1 of the paper:\n",
        "        #   We use a random Gaussian initialization for A and zero for B, so ∆W = BA is zero at the beginning of training\n",
        "        self.lora_A = nn.Parameter(torch.zeros((rank,features_out)).to(device))\n",
        "        self.lora_B = nn.Parameter(torch.zeros((features_in, rank)).to(device))\n",
        "        nn.init.normal_(self.lora_A, mean=0, std=1)\n",
        "\n",
        "        # Section 4.1 of the paper:\n",
        "        #   We then scale ∆Wx by α/r , where α is a constant in r.\n",
        "        #   When optimizing with Adam, tuning α is roughly the same as tuning the learning rate if we scale the initialization appropriately.\n",
        "        #   As a result, we simply set α to the first r we try and do not tune it.\n",
        "        #   This scaling helps to reduce the need to retune hyperparameters when we vary r.\n",
        "        self.scale = alpha / rank\n",
        "        self.enabled = True\n",
        "\n",
        "    def forward(self, original_weights):\n",
        "        if self.enabled:\n",
        "            # Return W + (B*A)*scale\n",
        "            return original_weights + torch.matmul(self.lora_B, self.lora_A).view(original_weights.shape) * self.scale\n",
        "        else:\n",
        "            return original_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add the parameterization to our network."
      ],
      "metadata": {
        "id": "dBiwRmyafLhT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Sr_4K42KW-Vm"
      },
      "outputs": [],
      "source": [
        "import torch.nn.utils.parametrize as parametrize\n",
        "\n",
        "def linear_layer_parameterization(layer, device, rank=1, lora_alpha=1):\n",
        "    # Only add the parameterization to the weight matrix, ignore the Bias\n",
        "\n",
        "    # From section 4.2 of the paper:\n",
        "    #   We limit our study to only adapting the attention weights for downstream tasks and freeze the MLP modules (so they are not trained in downstream tasks) both for simplicity and parameter-efficiency.\n",
        "    #   [...]\n",
        "    #   We leave the empirical investigation of [...], and biases to a future work.\n",
        "\n",
        "    features_in, features_out = layer.weight.shape\n",
        "    return LoRAParametrization(\n",
        "        features_in, features_out, rank=rank, alpha=lora_alpha, device=device\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parametrize.register_parametrization(\n",
        "    model.linear1, \"weight\", linear_layer_parameterization(model.linear1, device)\n",
        ")\n",
        "parametrize.register_parametrization(\n",
        "    model.linear2, \"weight\", linear_layer_parameterization(model.linear2, device)\n",
        ")\n",
        "parametrize.register_parametrization(\n",
        "    model.linear3, \"weight\", linear_layer_parameterization(model.linear3, device)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgIfe3hwfolc",
        "outputId": "4f25fe65-af38-4cb3-b40d-20d150c7a012"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ParametrizedLinear(\n",
              "  in_features=2000, out_features=10, bias=True\n",
              "  (parametrizations): ModuleDict(\n",
              "    (weight): ParametrizationList(\n",
              "      (0): LoRAParametrization()\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def enable_disable_lora(enabled=True):\n",
        "    for layer in [model.linear1, model.linear2, model.linear3]:\n",
        "        layer.parametrizations[\"weight\"][0].enabled = enabled"
      ],
      "metadata": {
        "id": "FP9ZR9YEf346"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display the number of parameters added by LoRA."
      ],
      "metadata": {
        "id": "tlosnVTOgBwg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_parameters_lora = 0\n",
        "total_parameters_non_lora = 0\n",
        "for index, layer in enumerate([model.linear1, model.linear2, model.linear3]):\n",
        "    total_parameters_lora += layer.parametrizations[\"weight\"][0].lora_A.nelement() + layer.parametrizations[\"weight\"][0].lora_B.nelement()\n",
        "    total_parameters_non_lora += layer.weight.nelement() + layer.bias.nelement()\n",
        "    print(\n",
        "        f'Layer {index+1}: W: {layer.weight.shape} + B: {layer.bias.shape} + Lora_A: {layer.parametrizations[\"weight\"][0].lora_A.shape} + Lora_B: {layer.parametrizations[\"weight\"][0].lora_B.shape}'\n",
        "    )\n",
        "# The non-LoRA parameters count must match the original network\n",
        "assert total_parameters_non_lora == total_parameters_original\n",
        "\n",
        "print(f'Total number of parameters (original): {total_parameters_non_lora:,}')\n",
        "print(f'Total number of parameters (original + LoRA): {total_parameters_lora + total_parameters_non_lora:,}')\n",
        "print(f'Parameters introduced by LoRA: {total_parameters_lora:,}')\n",
        "parameters_incremment = (total_parameters_lora / total_parameters_non_lora) * 100\n",
        "print(f'Parameters incremment: {parameters_incremment:.3f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3JsvsHTf-3i",
        "outputId": "5995bc98-bf3c-4c04-b96a-b5ce54f31194"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer 1: W: torch.Size([1000, 784]) + B: torch.Size([1000]) + Lora_A: torch.Size([1, 784]) + Lora_B: torch.Size([1000, 1])\n",
            "Layer 2: W: torch.Size([2000, 1000]) + B: torch.Size([2000]) + Lora_A: torch.Size([1, 1000]) + Lora_B: torch.Size([2000, 1])\n",
            "Layer 3: W: torch.Size([10, 2000]) + B: torch.Size([10]) + Lora_A: torch.Size([1, 2000]) + Lora_B: torch.Size([10, 1])\n",
            "Total number of parameters (original): 2,807,010\n",
            "Total number of parameters (original + LoRA): 2,813,804\n",
            "Parameters introduced by LoRA: 6,794\n",
            "Parameters incremment: 0.242%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Freeze all the parameters of the original network and only fine tuning the ones introduced by LoRA. Then fine-tune the model on the class 6 and only for 100 batches."
      ],
      "metadata": {
        "id": "Ynx-DsVJg4iB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze the non-Lora parameters\n",
        "for name, param in model.named_parameters():\n",
        "    if 'lora' not in name:\n",
        "        print(f'Freezing non-LoRA parameter {name}')\n",
        "        param.requires_grad = False\n",
        "\n",
        "# Load the FashionMNIST dataset again, by keeping only the class 6\n",
        "fmnist_trainset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
        "exclude_indices = fmnist_trainset.targets == 6\n",
        "fmnist_trainset.data = fmnist_trainset.data[exclude_indices]\n",
        "fmnist_trainset.targets = fmnist_trainset.targets[exclude_indices]\n",
        "print(fmnist_trainset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxKOsB_JgWlo",
        "outputId": "b32fea58-590c-49f4-c48b-38388c91c95d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Freezing non-LoRA parameter linear1.bias\n",
            "Freezing non-LoRA parameter linear1.parametrizations.weight.original\n",
            "Freezing non-LoRA parameter linear2.bias\n",
            "Freezing non-LoRA parameter linear2.parametrizations.weight.original\n",
            "Freezing non-LoRA parameter linear3.bias\n",
            "Freezing non-LoRA parameter linear3.parametrizations.weight.original\n",
            "Dataset FashionMNIST\n",
            "    Number of datapoints: 6000\n",
            "    Root location: ./data\n",
            "    Split: Train\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               ToTensor()\n",
            "               Normalize(mean=(0.1307,), std=(0.3081,))\n",
            "           )\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dataloader for the training\n",
        "train_loader = torch.utils.data.DataLoader(fmnist_trainset, batch_size=10, shuffle=True)\n",
        "\n",
        "# Train the network with LoRA only on the class 6 and only for 100 batches (hoping that it would improve the performance on the class 6)\n",
        "train(train_loader, model, epochs=1, total_iterations_limit=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDOUQwakhYep",
        "outputId": "95568ea6-1ae4-452b-b156-036656f7bafd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  99%|█████████▉| 99/100 [00:00<00:00, 109.67it/s, loss=0.0828]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verify that the fine-tuning didn't alter the original weights, but only the ones introduced by LoRA."
      ],
      "metadata": {
        "id": "z57a91drh2Ll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check that the frozen parameters are still unchanged by the finetuning\n",
        "assert torch.all(model.linear1.parametrizations.weight.original == original_weights['linear1.weight'])\n",
        "assert torch.all(model.linear2.parametrizations.weight.original == original_weights['linear2.weight'])\n",
        "assert torch.all(model.linear3.parametrizations.weight.original == original_weights['linear3.weight'])\n",
        "\n",
        "enable_disable_lora(enabled=True)\n",
        "# The new linear1.weight is obtained by the \"forward\" function of our LoRA parametrization\n",
        "# The original weights have been moved to model.linear1.parametrizations.weight.original\n",
        "# More info here: https://pytorch.org/tutorials/intermediate/parametrizations.html#inspecting-a-parametrized-module\n",
        "assert torch.equal(model.linear1.weight, model.linear1.parametrizations.weight.original + (model.linear1.parametrizations.weight[0].lora_B @ model.linear1.parametrizations.weight[0].lora_A) * model.linear1.parametrizations.weight[0].scale)\n",
        "\n",
        "enable_disable_lora(enabled=False)\n",
        "# If we disable LoRA, the linear1.weight is the original one\n",
        "assert torch.equal(model.linear1.weight, original_weights['linear1.weight'])"
      ],
      "metadata": {
        "id": "Y9R12y2rhrC_"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test the network with LoRA enabled (the class 6 should be classified better)"
      ],
      "metadata": {
        "id": "5X-AKYo2j5K0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test with LoRA enabled\n",
        "enable_disable_lora(enabled=True)\n",
        "test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZ6h5sMbj2SV",
        "outputId": "c49bd0a0-870a-44f7-a8e3-0d04514ffb64"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 625/625 [00:03<00:00, 179.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.718\n",
            "wrong counts for the class 0: 862\n",
            "wrong counts for the class 1: 26\n",
            "wrong counts for the class 2: 559\n",
            "wrong counts for the class 3: 518\n",
            "wrong counts for the class 4: 646\n",
            "wrong counts for the class 5: 16\n",
            "wrong counts for the class 6: 46\n",
            "wrong counts for the class 7: 36\n",
            "wrong counts for the class 8: 76\n",
            "wrong counts for the class 9: 37\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test the network with LoRA disabled (the accuracy and errors counts must be the same as the original network)"
      ],
      "metadata": {
        "id": "nE0wdUWrkIef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test with LoRA disabled\n",
        "enable_disable_lora(enabled=False)\n",
        "test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhJ6LgT7j8dF",
        "outputId": "da6c4aff-495c-4923-c36d-0d7b5ff50a77"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 625/625 [00:03<00:00, 198.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.886\n",
            "wrong counts for the class 0: 156\n",
            "wrong counts for the class 1: 17\n",
            "wrong counts for the class 2: 158\n",
            "wrong counts for the class 3: 132\n",
            "wrong counts for the class 4: 200\n",
            "wrong counts for the class 5: 22\n",
            "wrong counts for the class 6: 348\n",
            "wrong counts for the class 7: 40\n",
            "wrong counts for the class 8: 37\n",
            "wrong counts for the class 9: 34\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "99RlqvyXkLAj"
      },
      "execution_count": 19,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}